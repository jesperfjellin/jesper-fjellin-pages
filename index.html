<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jesper Fjellin's Github Pages</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    <style>
        /* General Styles */
        :root {
            --primary-color: #2d2d2d;     /* Dark gray */
            --secondary-color: #a0a0a0;   /* Medium gray for text */
            --accent-color: #FF9900;      /* Neon orange from your Ridge.py (1.0, 0.6, 0.0) */
            --text-color: #ffffff;        /* White text */
            --bg-color: #1a1a1a;         /* Dark background */
            --card-bg: #2f2f2f;          /* Slightly lighter than background */
            --shadow: 0 8px 30px rgba(0, 0, 0, 0.2);
            --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }

        body {
            font-family: 'Inter', 'Segoe UI', sans-serif, 'Ubuntu';
            line-height: 1.7;
            margin: 0;
            padding: 0;
            background-color: var(--bg-color);
            color: var(--text-color);
        }

        .header-content h1, .title, .github-links .btn {
            background: rgba(0, 0, 0, 0.5); /* Light black background */
            padding: 10px 20px;
            border-radius: 8px;
            color: #fff;
            display: inline-block;
        }

        a {
            color: var(--accent-color);
            text-decoration: none;
            transition: all 0.3s ease;
            border-bottom: 1px solid transparent;
        }
        html {
            scroll-behavior: smooth;
        }

        a:hover {
            color: #c0392b;  /* Darker red on hover */
            border-bottom-color: var(--secondary-color);
        }

        /* Modern Header */
        header {
            height: 100vh;
            background: url('images/Mount_Everest.png') center/contain;
            background-color: #111111;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            position: relative;
            background-repeat: no-repeat;
            padding: 0; /* Remove or minimize padding */
        }

        .header-content {
            text-align: center;
            max-width: 800px;
            padding: 20px 40px; /* Adjust the top padding to move content down */
            position: relative;
            margin-top: -150px; /* Use margin to move the content down */
        }

        .header-content::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 120%;
            height: 120%;
            background: radial-gradient(circle, rgba(0,0,0,0.2) 0%, rgba(0,0,0,0) 70%);
            z-index: -1;
        }

        .header-content h1 {
            font-size: 4.5em;
            margin: 0 0 60px 0;
            letter-spacing: -0.02em;
            color: #fff;
            background: rgba(0, 0, 0, 0);
            padding: 2px 25px;
            border-radius: 12px;
            display: inline-block;
            line-height: 1.2;
        }

        .title {
            font-size: 1.5em;
            color: #fff;
            margin: 0 0 40px 0;
            background: rgba(0, 0, 0, 0);
            padding: 3px 15px;
            border-radius: 8px;
            display: inline-block;
            line-height: 1.5;
        }

        .github-links {
            background: none;
            padding: 0;
            display: flex;
            gap: 20px;
            justify-content: center;
        }

        .btn {
            display: inline-block;
            padding: 10px 25px;
            background: rgba(0, 0, 0, 0.3);
            color: #fff;
            border-radius: 30px;
            backdrop-filter: blur(5px);
            transition: var(--transition);
        }

        .btn:hover {
            background: rgba(45, 52, 54, 1.20);
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        /* Scroll Indicator */
        .scroll-indicator {
            position: absolute;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            text-align: center;
            color: #fff;
        }

        .mouse {
            width: 30px;
            height: 50px;
            border: 2px solid #fff;
            border-radius: 20px;
            margin: 0 auto 10px;
            position: relative;
        }

        .mouse::before {
            content: '';
            width: 4px;
            height: 8px;
            background: #fff;
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            top: 8px;
            border-radius: 2px;
            animation: scroll 2s infinite;
        }

        /* Project Navigation */
        .project-nav {
            position: sticky;
            top: 20px;
            width: 200px;
            float: left;
        }

        .project-nav ul {
            list-style: none;
            padding: 0;
        }

        .project-nav a {
            display: block;
            padding: 15px 20px;
            color: var(--secondary-color);
            border-left: 3px solid transparent;
            transition: var(--transition);
        }

        .project-nav a.active,
        .project-nav a:hover {
            color: var(--text-color);
            border-left-color: var(--accent-color);
            background: rgba(255, 153, 0, 0.1); /* Very subtle orange background */
        }

        /* Projects Container */
        .projects-container {
            margin-left: 240px;
            padding: 40px 0;
        }

        .project {
            background: var(--card-bg);
            border-radius: 20px;
            padding: 40px;
            margin-bottom: 60px;
            border-left: none;
            position: relative;
            overflow: hidden;
        }

        .project::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: linear-gradient(90deg, var(--accent-color), transparent);
        }

        .project h2 {
            font-size: 2.2em;
            color: var(--text-color);
            border-bottom: none;
            letter-spacing: -0.01em;
            margin-top: 0;
            padding-bottom: 15px;
            margin-bottom: 20px;
        }

        .project p {
            margin-bottom: 10px;
            color: var(--text-color);
        }

        .project iframe {
            border: none;
            width: 100%;
            height: 400px;
            border-radius: 12px;
            margin-bottom: 10px;
            box-shadow: var(--shadow);
        }

        /* Centered Content */
        .centered-content {
            padding: 10px;
            margin: 0 auto 20px auto;
            width: 80%;
            text-align: center;
        }

        .centered-content img {
            max-width: 100%;
            border-radius: 14px;
            box-shadow: var(--shadow);
            transition: var(--transition);
            margin-top: 10px;
        }

        .centered-content img:hover {
            transform: scale(1.02);
        }

        .centered-content p {
            margin-top: 10px;
            font-size: 0.9em;
            color: var(--text-color);
        }

        /* Features Section */
        .features {
            margin-top: 20px;
        }

        .features h3 {
            font-size: 1.6em;
            color: var(--secondary-color);
            border-bottom: 1px solid #ddd;
            padding-bottom: 5px;
        }

        .feature-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
        }

        .feature-card {
            background: var(--card-bg);
            padding: 25px;
            border-radius: 12px;
            margin-bottom: 20px;
            transition: var(--transition);
            border: 1px solid rgba(233, 232, 232, 0.822);
        }

        .feature-card h4 {
            margin: 0 0 15px 0;
            color: var(--text-color);
            font-size: 1.2em;
        }

        .feature-card p {
            margin: 0 0 20px 0;
            color: var(--secondary-color);
        }

        .view-code-btn {
            background: none;
            border: none;
            color: var(--accent-color);
            cursor: pointer;
            font-size: 0.9em;
            padding: 0;
            transition: var(--transition);
        }

        .view-code-btn:hover {
            color: var(--secondary-color);
        }

        /* Modal Styles */
        .code-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100vh;
            background: rgba(0, 0, 0, 0.5);
            backdrop-filter: blur(5px);
            z-index: 1000;
        }

        .code-modal.active {
            display: flex !important;
            align-items: center;
            justify-content: center;
        }

        .modal-content {
            background: var(--card-bg);
            width: 95%;
            max-width: 1200px;
            height: 80vh;
            border-radius: 12px;
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.15);
            display: flex;
            flex-direction: column;
            position: fixed;
            top: 20%;
            left: 50%;
            transform: translate(-50%, -50%);
        }

        .modal-header h3 {
            margin: 0;
            font-size: 1.2em;
            color: var(--bg-color);  /* Dark background color for contrast */
            /* or you could use a specific color like: */
            /* color: #1a1a1a; */
        }

        .modal-header {
            padding: 12px 16px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: #ffffff;  /* Ensure white background */
        }

        .close-modal {
            background: none;
            border: none;
            font-size: 1.5em;
            cursor: pointer;
            color: var(--secondary-color);
            transition: var(--transition);
        }

        .close-modal:hover {
            color: var(--text-color);
        }

        .modal-body {
            flex: 1;
            padding: 0;
            overflow: hidden;
        }

        .modal-body pre {
            height: 100%;
            margin: 0;
            border-radius: 0;
        }

        .modal-body code {
            color: #fff;
            font-family: 'Fira Code', monospace;
            font-size: 0.9em;
        }

        /* Optional: Customize some Prism styles */
        .modal-body .token.comment {
            color: #6a9955;  /* Brighter green for comments */
        }

        .modal-body .token.string {
            color: #ce9178;  /* Softer orange for strings */
        }

        .modal-body .token.keyword {
            color: #569cd6;  /* Bright blue for keywords */
        }

        .modal-body .token.function {
            color: #dcdcaa;  /* Yellow for functions */
        }

        /* Responsive Design */
        @media (max-width: 1024px) {
            .project-nav {
                width: 100%;
                float: none;
                position: relative;
                margin-bottom: 40px;
            }

            .project-nav ul {
                display: flex;
                overflow-x: auto;
                padding: 10px;
            }

            .projects-container {
                margin-left: 0;
            }
        }

        @keyframes scroll {
            0% { transform: translate(-50%, 0); opacity: 1; }
            100% { transform: translate(-50%, 15px); opacity: 0; }
        }


        .modal-content {
            background-color: #fefefe;
            margin: 15% auto;
            padding: 20px;
            border: 1px solid #888;
            width: 80%;
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }

        .modal-header h3 {
            margin: 0;
            font-size: 1.5em;
        }

        .close-modal {
            color: #aaa;
            font-size: 28px;
            font-weight: bold;
        }

        .close-modal:hover,
        .close-modal:focus {
            color: black;
            text-decoration: none;
            cursor: pointer;
        }

        .modal-body {
            padding: 20px;
        }

        .view-code-btn {
            display: inline-block;
            margin-top: 10px;
            color: var(--accent-color);
            text-decoration: none;
            font-size: 0.9em;
        }

        .view-code-btn:hover {
            text-decoration: underline;
        }

        /* Add this to your CSS */
        body.modal-open {
            overflow: hidden;
        }

        .blog-section {
            margin-top: 30px;
        }

        .blog-section h3 {
            color: var(--text-color);
            font-size: 1.6em;
            margin: 40px 0 20px 0;
        }

        .blog-section p {
            margin-bottom: 20px;
            line-height: 1.8;
        }

        .blog-section ul {
            margin: 20px 0;
            padding-left: 25px;
        }

        .blog-section li {
            margin-bottom: 12px;
            line-height: 1.6;
            color: var(--text-color);
        }

        .blog-section .centered-content {
            margin: 40px auto;
        }
    </style>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Jesper Fjellin</h1>
            <p class="title">GIS Developer & Engineer</p>
            <div class="github-links">
                <a href="https://github.com/jesperfjellin" target="_blank" class="btn">GitHub</a>
                <a href="https://www.linkedin.com/in/jesper-fjellin/" target="_blank" class="btn">Linkedin</a>
            </div>
        </div>
        <div class="scroll-indicator">
            <div class="mouse"></div>
            <span>Scroll to explore</span>
        </div>
    </header>

    <div class="container">
        <nav class="project-nav">
            <ul>
                <li><a href="#dbfriend" class="active">dbfriend</a></li>
                <li><a href="#sosilogikk">Sosilogikk</a></li>
                <li><a href="#Delta-Encoding-and-MongoDB">Delta Encoding and MongoDB</a></li>
                <li><a href="#Docker-in-Production-Environments">Docker in Production Environments</a></li>
                <li><a href="#rust-bindings">Rust Bindings in Python</a></li>
                <li><a href="#topology-testing">Building Custom Topology Testing Solutions</a></li>
            </ul>
        </nav>
        
        <div class="projects-container">
            <!-- Project 1 -->
            <div class="project" id="dbfriend">
                <h2>dbfriend - PostGIS Database Management</h2>
                <p>dbfriend is a Python command-line tool designed to simplify the loading and synchronization of spatial data into PostGIS databases. It focuses on data integrity and safety, ensuring that your database operations are reliable and efficient. By handling complex tasks intelligently, dbfriend helps GIS professionals and database administrators streamline their workflows. <a href="https://github.com/jesperfjellin/dbfriend" target="_blank">Github repo</a></p>
                
                <!-- Feature Cards -->
                <div class="features">
                    <h3>Key Features</h3>
                    <div class="feature-cards">
                        <div class="feature-card">
                            <h4>Transactional Operations</h4>
                            <p>All database operations are executed within transactions, ensuring data integrity and automatic rollback on failure.</p>
                            <button class="view-code-btn" data-feature="transactions">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Automated Table Backups</h4>
                            <p>dbfriend automatically creates backups before modifying any existing tables, keeping up to three historical versions per table for easy restoration and added data safety.</p>
                            <button class="view-code-btn" data-feature="backups">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Supports Multiple Vector Formats</h4>
                            <p>Load data from various spatial file formats, including GeoJSON, Shapefile, GeoPackage, KML, and GML, providing flexibility in handling different data sources.</p>
                            <button class="view-code-btn" data-feature="support-formats">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Intelligent Geometry Comparison</h4>
                            <p>Prevent duplicates and ensure data consistency by comparing geometries using hashes to detect new, updated, and identical features efficiently.</p>
                            <button class="view-code-btn" data-feature="geometry-comparison">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Attribute-Aware Updates</h4>
                            <p>Update existing geometries based on attribute changes, so your database always reflects the most current data.</p>
                            <button class="view-code-btn" data-feature="attribute-updates">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Automatic Geometry Handling</h4>
                            <p>Automatically detects and renames geometry columns to a standard format, simplifying data processing and integration.</p>
                            <button class="view-code-btn" data-feature="geometry-handling">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>CRS Compatibility Checks and Automatic Reprojection</h4>
                            <p>Verifies CRS compatibility and automatically reprojects data as needed, ensuring spatial data aligns correctly within your database.</p>
                            <button class="view-code-btn" data-feature="crs-handling">View Implementation →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Spatial Index Creation for Optimized Queries</h4>
                            <p>Automatically creates spatial indexes on imported data, improving query performance and data retrieval speeds.</p>
                            <button class="view-code-btn" data-feature="spatial-index">View Implementation →</button>
                        </div>
                    </div>
                    <h3>Demonstration</h3>
                    <div class="centered-content">
                        <img src="images/yO1AG6bL86.gif" alt="Demonstration of dbfriend in action" 
                            style="max-width: 100%; width: 800px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                        <p style="color: var(--secondary-color); font-size: 0.9em;">dbfriend in action: processing spatial files and managing PostGIS database operations.</p>
                    </div>
                </div>
            </div>

            <!-- Project 2 -->
            <div class="project" id="sosilogikk">
                <h2>Sosilogikk</h2>
                <p>Sosilogikk is a Python module intended to streamline the use of Python libraries like Shapely or Fiona for GIS analyses, on the Norwegian vector data format SOSI (Samordnet Opplegg for Stedfestet Informasjon). Sosilogikk allows the user to seamlessly load a .SOS file into a GeoPandas GeoDataFrame through only a few lines of code. <a href="https://github.com/jesperfjellin/sosilogikk" target="_blank">Github repo</a></p>
                
                <div class="centered-content">
                    <img src="images/SOSI-file.png" alt="Example SOSI-file">
                    <p>Example structure of a vector object in a SOSI-file. The dot- and coordinates-format makes it difficult to use with Python libraries.</p>
                </div>
            
                <div class="centered-content">
                    <img src="images/GDF_sosi.png" alt="Example SOSI-file loaded into GeoDataFrame">
                    <p>Sosilogikk applied to a large SOSI-file, resulting in an excel-like table.</p>
                </div>
            
                <p>Using the .to_file method, you can easily export the GeoDataFrame to any OGR-supported vector format, allowing software like ArcGIS or QGIS to be used.</p>
                
                <div class="centered-content">
                    <img src="images/flatgeobuf_dreneringslinjer.png" alt="Drainage lines in Flatgeobuf format visualized in QGIS" style="max-width:50%;">
                    <p>Drainage lines in Flatgeobuf format visualized in QGIS.</p>
                </div>
            </div>

            <!-- Project 3 -->
            <div class="project" id="Delta-Encoding-and-MongoDB">
                <h2>Delta Encoding and MongoDB - Optimizing for Cloud Computing</h2>
                <p>Modern cloud-native GIS applications often need to efficiently store and transmit large volumes of geographic data between services. While GeoJSON is the standard format for geographic data exchange, its text-based nature makes it suboptimal for cloud storage and transmission. This solution combines MongoDB's BSON format with delta encoding to create a highly efficient geographic data pipeline. <a href="https://github.com/jesperfjellin/bson_encoding" target="_blank">Github repo</a></p>
            
                <div class="blog-section">
                    <h3>BSON and MongoDB in Cloud Computing</h3>
                    <p>BSON (Binary JSON) is MongoDB's binary format, specifically designed for cloud-scale data operations. Unlike traditional JSON, BSON provides native support for different numeric types and binary data, making it ideal for geographic coordinate storage. This becomes particularly important in microservice architectures where data needs to be efficiently serialized, transmitted, and stored across different cloud services. In cloud environments where MongoDB Atlas is increasingly common, this native format compatibility translates to significant performance benefits and reduced processing costs.</p>
                    
                    <h3>Understanding Delta Encoding</h3>
                    <p>Delta encoding is a compression technique that stores the differences (deltas) between consecutive values rather than the values themselves. For geographic coordinates, this is particularly effective because consecutive points in a geometry are typically close to each other, resulting in small delta values that require fewer bits to store.</p>
            
                    <div class="centered-content">
                        <img src="images/delta_encoding.png" alt="Delta encoding visualization">
                        <p>Visualization of delta encoding: Starting with a sequence of numbers (top row), we compute the differences between consecutive values (second row). Negative differences are then shifted to positive values (third row) for efficient binary representation (bottom row). This process significantly reduces storage requirements while maintaining perfect reversibility. (Adapted from Xia et al., The VLDB Journal, 2024)</p>
                    </div>
            
                    <h3>Implementation Approach</h3>
                    <p>The implementation in BSON_encoder.py follows these key steps:</p>
                    <ol>
                        <li><strong>Scale and Convert to Integers:</strong> First, we scale the floating-point coordinates (typically by 1e6) and convert them to integers to preserve precision while enabling efficient delta calculations.</li>
                        <li><strong>Calculate Deltas:</strong> For each point after the first, we store the difference from the previous point rather than the absolute coordinates.</li>
                        <li><strong>BSON Serialization:</strong> The delta-encoded coordinates are then serialized to BSON format, which provides efficient storage of integer arrays.</li>
                        <li><strong>GZIP Compression:</strong> Finally, we apply GZIP compression to further reduce the size of the encoded data.</li>
                    </ol>
            
                    <p>Here's a simplified example showing the transformation:</p>
                    <pre><code class="language-json">
            Original coordinates: [(100.123456, 50.123456), (100.123476, 50.123476)]
            After scaling by 1e6: [(100123456, 50123456), (100123476, 50123476)]
            Delta encoded: [(100123456, 50123456), (20, 20)]  # Second point stored as difference
                    </code></pre>
            
                    <h3>Compressions Results</h3>
                    <p>In modern cloud architectures, geographic data flows between various services - from storage to processing to web APIs. This combined approach of delta encoding and BSON serialization dramatically reduces the bandwidth required for these operations. Testing with real-world infrastructure data:</p>
            
                    <div class="centered-content">
                        <img src="images/encoding_results.png" alt="Data size comparison between GeoJSON and BSON formats">
                        <p>Comparison of data sizes: Original GeoJSON format vs BSON-encoded format with delta compression. The combined approach reduces the file size by almost 90% while maintaining full coordinate precision.</p>
                    </div>
            
                    <h3>Cloud Integration Benefits</h3>
                    <p>While the size reduction is impressive, the real value lies in the format's cloud-native nature. The compressed data remains fully compatible with MongoDB's geospatial queries and indexes, allowing for efficient spatial operations directly on the compressed data. The compression is completely reversible, and the flattened GeoJSON structure results in smaller file sizes even after decompression.</p>
            

                </div>
            </div>

            <!-- Project 4 -->
            <div class="project" id="Docker-in-Production-Environments">
                <h2>Docker in Production Environments - Bridging Technical Gaps</h2>
                <p>Working in GIS production environments has highlighted an interesting challenge: the gap between what can be automated and what typically is automated. While tools like ArcGIS and QGIS excel at interactive analysis, many workflows would benefit from programmatic automation - yet often remain manual processes.</p>
            
                <div class="blog-section">
                    <h3>The Automation Challenge in GIS</h3>
                    <p>GIS workflows frequently involve repetitive tasks that are perfect candidates for automation:</p>
                    <ul>
                        <li>Database-wide topology validation and error checking</li>
                        <li>Scheduled quality control processes</li>
                        <li>Statistical aggregation of incoming project data</li>
                        <li>Automated spatial sampling and analysis</li>
                    </ul>
                    <p>The challenge isn't identifying what to automate - it's making automation accessible to GIS professionals who may not have programming experience. This is where Docker has proven particularly valuable.</p>
            
                    <h3>Docker as a Bridge</h3>
                    <p>Docker's containerization approach solves several fundamental challenges in GIS automation:</p>
                    <ul>
                        <li>It eliminates the complexity of Python environment management</li>
                        <li>It ensures consistent spatial libraries across different machines</li>
                        <li>It packages all dependencies in a single, shareable unit</li>
                        <li>Most importantly, it makes advanced automation accessible to non-programmers</li>
                    </ul>
            
                    
            
                    <h3>From Theory to Practice</h3>
                    <p>In practice, implementing Docker in a GIS environment involves creating a layer of abstraction between the technical complexity and the end user. The implementation typically involves wrapping Docker commands in a user-friendly interface - the user doesn't need to understand the underlying system, they simply interact with familiar buttons and inputs while Docker handles the complex environment management behind the scenes. To accomplish this, we can create a launcher script in the form of a batch file that presents the user with inputs through a simple graphical user interface. As I work in an environment where Python comes pre-installed, I chose to use a Python script for this task. </p>

                    <div class="centered-content">
                        <img src="images/docker_launcher.png" alt="Docker-based GIS tool launcher interface">
                        <p>Example of a Docker-based GIS tool launcher in Python that abstracts away the complexity of container management and environment setup.</p>
                    </div>
            
                    <h3>Reflections on Production Use</h3>
                    <p>Using Docker in production has revealed several interesting insights:</p>
                    <ul>
                        <li>Environment Consistency: The "it works on my machine" problem essentially disappears</li>
                        <li>Version Management: Docker images provide a reliable way to track and roll back changes</li>
                        <li>Distribution: Updates to spatial analysis tools can be pushed through Docker Hub without requiring end-user intervention</li>
                        <li>Isolation: Each process runs in its own container, preventing system-wide conflicts</li>
                    </ul>
            
                    <h3>Looking Forward</h3>
                    <p>The integration of Docker in GIS workflows opens interesting possibilities for the future of spatial data processing. As cloud infrastructure becomes more prevalent in GIS, containerized workflows could become the standard way of handling automated spatial analysis. The key will be maintaining the balance between powerful automation capabilities and user-friendly interfaces.</p>
                </div>
            </div>
            <!-- Project 5 -->
            <div class="project" id="rust-bindings">
                <h2>Rust Bindings in Python - When Fast Data Processing Matters</h2>
                <p>Python is a powerful language for rapid development, especially in the GIS domain, thanks to libraries like GeoPandas and Shapely. However, when processing large datasets or performing complex calculations, Python's speed can become a limitation. This is where Rust comes in - offering the speed we need while letting us keep Python's ease of use.</p>
            
                <div class="blog-section">
                    <h3>Understanding Rust Bindings</h3>
                    <p>Bindings are essentially a way to connect two different programming languages, allowing them to work together. In this case, we use Rust bindings to integrate Rust's high-performance capabilities into Python workflows. This means we can write the most performance-critical parts of our GIS analysis in Rust, while still using Python for the overall workflow.</p>
            
                    <h3>Why Use Rust?</h3>
                    <p>Many traditional GIS tools are written in C++, and for good reason - C++ offers excellent performance and has been the go-to language for computationally intensive tasks for decades. However, Rust brings some unique advantages to the table. While matching C++'s performance, Rust's compiler enforces memory safety and thread safety at compile time, preventing many common programming errors before they can become runtime bugs. This is particularly valuable when working with large spatial datasets where data integrity is crucial.</p>
                    <p>Additionally, Rust's modern tooling and package management system makes it easier to create and maintain bindings compared to C++. The language's focus on safe concurrency also makes it particularly well-suited for parallel processing of spatial data, an increasingly important consideration as datasets continue to grow in size and complexity.</p>
            
                    <h3>Performance Comparison</h3>
                    <p>To demonstrate the performance difference between Python and Rust, I performed a simple GIS task: creating buffers around 1 million point geometries, and checking how many of the buffers overlapped with each other. The results were striking - the Rust implementation completed in just 2 seconds, while the Python version took 84 seconds to finish the same task.</p>

                    <div class="centered-content">
                        <img src="images/rust_performance.png" alt="Buffer analysis performance comparison">
                        <p>Results from the performance comparison.</p>
                    </div>
                    
                    <div class="feature-cards">
                        <div class="feature-card">
                            <h4>Rust Implementation Highlights</h4>
                            <p>The key features that make this implementation fast:</p>
                            <button class="view-code-btn" data-feature="rust-parallel">Parallel Processing →</button>
                        </div>
                        <div class="feature-card">
                            <h4>Python Integration</h4>
                            <p>How we expose the Rust function to Python:</p>
                            <button class="view-code-btn" data-feature="rust-binding">Binding Setup →</button>
                        </div>
                    </div>
                    
                    <h3>Integrating Rust with Python</h3>
                    <p>By incorporating Rust into a Python-based workflow, we can leverage the strengths of both languages. Python remains the glue that holds the workflow together, providing ease of use and flexibility, while Rust handles the heavy lifting where performance is critical. This combination allows us to build robust GIS applications that are both user-friendly and highly efficient.</p>
                </div>
            </div>

            <!-- Project 6 -->
            <div class="project" id="topology-testing">
                <h2>Building Custom Topology Testing Solutions</h2>
                <p>An exploration of why and how to build custom topology validation tools in an era of increasingly complex geospatial data relationships. While traditional GIS tools offer built-in topology checks, modern spatial data often requires more nuanced, domain-specific validation rules. <a href="https://github.com/jesperfjellin/DIY_topology" target="_blank">Github repo</a></p>
            
                <div class="blog-section">
                    <h3>Why Custom Topology Testing?</h3>
                    <p>As geospatial data becomes more complex, the relationships between features often extend beyond simple geometric rules. For example, a road intersection might be valid or invalid based on multiple factors:</p>
                    <ul>
                        <li>Physical infrastructure (bridges, tunnels)</li>
                        <li>Administrative classifications</li>
                        <li>Temporal constraints</li>
                        <li>Domain-specific business rules</li>
                    </ul>
                    <p>While tools like ArcGIS, QGIS, and PostGIS provide robust basic topology checks, they may not capture these nuanced relationships without significant customization.</p>
            
                    <h3>A Rule-Based Approach</h3>
                    <p>This project demonstrates how to build a flexible topology testing framework that separates validation rules from the validation logic. Using external configuration files, domain experts can define what constitutes a valid topological relationship:</p>
            
                    <pre class="line-numbers"><code class="language-json">
                        {
                            "global_settings": {
                                "id_attribute": "id",
                                "output_folder_name": "TopologyTest_Output",
                                "tolerances": {
                                    "gap": 0.001,
                                    "overlap": 0.001
                                },
                                "enabled_checks": {
                                    "intersections": true,
                                    "self_intersections": true,
                                    "gaps": true,
                                    "dangles": true,
                                    "overlaps": true,
                                    "containment": true
                                }
                            },
                            "dataset_rules": {
                                "roads": {
                                    "allow_intersection_if": [
                                        {
                                            "attribute": "terrain",
                                            "values": ["bridge", "tunnel", "air"]
                                        }
                                    ],
                                    "allow_overlap_if": [
                                        {
                                            "attribute": "type",
                                            "values": ["service_road", "emergency_lane"]
                                        }
                                    ],
                                    "check_dangles": true,
                                    "check_self_intersections": true
                                },
                                "buildings": {
                                    "allow_intersection_if": [],
                                    "allow_overlap_if": [],
                                    "check_gaps": true,
                                    "gap_tolerance": 0.5,
                                    "check_containment": true
                                }
                            }
                        }</code></pre>
            
                    <div class="centered-content">
                        <img src="images/topology_results.png" alt="Example of topology validation results">
                        <p>Terminal print of the topology validation results when two files are tested against rules set by the user.</p>
                    </div>
            
                    <h3>Implementation Strategy</h3>
                    <p>The framework demonstrates several key principles for custom topology testing:</p>
                    <ol>
                        <li><strong>Separation of Concerns:</strong> Keeping validation rules separate from the validation engine allows for easy updates as business rules evolve</li>
                        <li><strong>Attribute-Aware Validation:</strong> Moving beyond pure geometry to consider feature attributes and relationships</li>
                        <li><strong>Extensibility:</strong> A modular design that allows for adding new types of topology checks as needs arise</li>
                        <li><strong>Clear Reporting:</strong> Generating results that help users understand and fix topology issues in their specific context</li>
                    </ol>
            
                    <p>This approach shows how organizations can build tools that validate not just geometric correctness, but also domain-specific spatial relationships that matter to their business processes.</p>
                </div>
            </div>
    </div>
        </div>
    </div>

    <div class="code-modal" id="code-modal">
        <div class="modal-content">
            <div class="modal-header">
                <h3>Implementation</h3>
                <button class="close-modal">&times;</button>
            </div>
            <div class="modal-body">
                <pre><code class="language-python" id="transactions-code">
# Begin transaction for all operations
try:
    conn.autocommit = False

    # Initialize rich Progress
    with Progress(
        SpinnerColumn(),
        TextColumn("[cyan]{task.description:<30}"),
        BarColumn(bar_width=30),
        "[progress.percentage]{task.percentage:>3.0f}%",
        TimeElapsedColumn(),
        console=console,
        expand=False
    ) as progress:
        task = progress.add_task("       Processing files", total=len(file_info_list))

        for info in file_info_list:
            file = info['file']
            table_name = args.table if args.table else info['table_name']
            qualified_table = f"{schema}.{table_name}"
            gdf = info['gdf']

            try:
                logger.info(f"Processing {file}")

                # Handle geometry column naming
                if gdf.geometry.name != 'geom':
                    gdf = gdf.rename_geometry('geom')
                    gdf.set_geometry('geom', inplace=True)
                    gdf.set_crs(gdf.crs, inplace=True)

                # Ensure valid CRS
                if not gdf.crs:
                    logger.warning(f"No CRS found in {file}, defaulting to EPSG:4326")
                    gdf.set_crs(epsg=4326, inplace=True)

                if args.table:
                    # When using --table, only keep the geometry column
                    gdf = gdf[['geom']]

                    if table_name not in existing_tables:
                        # Get SRID from data or args
                        srid = args.epsg if args.epsg else gdf.crs.to_epsg()
                        if not srid:
                            srid = 4326  # Default to WGS84 if no SRID found

                        # Create table with generic geometry type and SRID
                        if create_generic_geometry_table(conn, engine, table_name, srid, schema):
                            existing_tables.append(table_name)
                        else:
                            continue

                        # For new tables, all geometries are new
                        logger.info(f"Found {format(len(gdf), ',').replace(',', ' ')} [green]new[/] geometries.")

                        # Append first batch of geometries
                        logger.info(f"Appending {format(len(gdf), ',').replace(',', ' ')} geometries to '{qualified_table}'")
                        if append_geometries(conn, engine, gdf, table_name, schema):
                            total_new += len(gdf)
                    else:
                        # Compare geometries before appending
                        new_geoms, updated_geoms, identical_geoms = compare_geometries(
                            gdf, conn, table_name, 'geom', schema=schema, exclude_columns=[], args=args
                        )

                        # Create summary of differences for this dataset
                        num_new = len(new_geoms) if new_geoms is not None else 0
                        num_updated = len(updated_geoms) if updated_geoms is not None else 0
                        num_identical = len(identical_geoms) if identical_geoms is not None else 0

                        logger.info(f"Found {format(num_new, ',').replace(',', ' ')} [green]new[/] geometries, "
                                    f"{format(num_updated, ',').replace(',', ' ')} [yellow]updated[/] geometries, and "
                                    f"{format(num_identical, ',').replace(',', ' ')} [red]identical[/] geometries skipped.")

                        if new_geoms is not None and not new_geoms.empty:
                            logger.info(f"Appending {format(len(new_geoms), ',').replace(',', ' ')} geometries to '{qualified_table}'")
                            # Use schema parameter in to_postgis
                            new_geoms.to_postgis(
                                name=table_name,
                                con=engine,
                                schema=schema,
                                if_exists='append',
                                index=False
                            )
                            total_new += len(new_geoms)

                        if identical_geoms is not None:
                            total_identical += len(identical_geoms)
                elif table_name in existing_tables:
                    logger.info(f"Table {qualified_table} exists, analyzing differences...")

                    # Get common columns between GDF and database table
                    common_columns = [col for col in gdf.columns if col != 'geom']
                    if not common_columns:
                        # If no common columns, just compare geometries
                        columns_sql = "MD5(ST_AsBinary(geom)) as geom_hash"
                    else:
                        quoted_columns = ', '.join(f'"{col}"' for col in common_columns)
                        columns_sql = f"MD5(ST_AsBinary(geom)) as geom_hash, {quoted_columns}"

                    # Check existing geometry column name in PostGIS
                    existing_geom_col = get_db_geometry_column(conn, table_name, schema=schema)

                    # Only keep 'geometry' if it's the existing column name, otherwise use 'geom'
                    target_geom_col = 'geometry' if existing_geom_col == 'geometry' else 'geom'

                    if gdf.geometry.name != target_geom_col:
                        logger.debug(f"Renaming geometry column from '{gdf.geometry.name}' to '{target_geom_col}'")
                        gdf = gdf.rename_geometry(target_geom_col)
                        gdf.set_geometry(target_geom_col, inplace=True)
                        gdf.set_crs(gdf.crs, inplace=True)  # Preserve CRS

                    new_geoms, updated_geoms, identical_geoms = compare_geometries(
                        gdf, conn, table_name, gdf.geometry.name, schema=schema, exclude_columns=exclude_cols, args=args
                    )

                    # Create summary of differences
                    num_new = len(new_geoms) if new_geoms is not None else 0
                    num_updated = len(updated_geoms) if updated_geoms is not None else 0
                    num_identical = len(identical_geoms) if identical_geoms is not None else 0

                    total_new += num_new
                    total_updated += num_updated
                    total_identical += num_identical

                    logger.info(f"Found {format(num_new, ',').replace(',', ' ')} [green]new[/] geometries, "
                                f"{format(num_updated, ',').replace(',', ' ')} [yellow]updated[/] geometries, and "
                                f"{format(num_identical, ',').replace(',', ' ')} [red]identical[/] geometries skipped. "
                                "Skipping identical geometries...")

                    # Handle new geometries
                    if num_new > 0:
                        try:
                            # Use schema parameter in to_postgis
                            new_geoms.to_postgis(
                                name=table_name,
                                con=engine,
                                schema=schema,
                                if_exists='append',
                                index=False
                            )
                            logger.info(f"Successfully appended {num_new} new geometries to {qualified_table}")
                        except Exception as e:
                            logger.error(f"Error appending new geometries: {e}")
                    else:
                        pass

                    # Handle updated geometries (if implemented)
                    if num_updated > 0:
                        update_geometries(updated_geoms, table_name, engine, unique_id_column='osm_id')  # Adjust unique_id_column as needed

                else:
                    num_geometries = len(gdf)
                    logger.info(f"Found {num_geometries} new geometries to import into new table '{qualified_table}'")

                    # Add coordinate printing for new tables
                    if args.coordinates:
                        for idx, row in gdf.iterrows():
                            print_geometry_details(row, "NEW", args.coordinates)

                    try:
                        # Write to PostGIS with schema
                        gdf.to_postgis(
                            name=table_name,  # Use unqualified name
                            con=engine,
                            schema=schema,    # Specify schema separately
                            if_exists='replace',
                            index=False
                        )

                        # Verify the table was created
                        cursor = conn.cursor()
                        cursor.execute("""
                            SELECT EXISTS (
                                SELECT 1
                                FROM information_schema.tables
                                WHERE table_schema = %s
                                AND table_name = %s
                            );
                        """, (schema, table_name))
                        table_exists = cursor.fetchone()[0]
                        cursor.close()

                        if table_exists:
                            logger.info(f"Successfully imported {num_geometries} geometries to new table '{qualified_table}'")
                            create_spatial_index(conn, table_name, schema=schema, geom_column='geom')
                            existing_tables.append(table_name)
                            total_new += num_geometries
                        else:
                            logger.error(f"Failed to create table '{qualified_table}'")

                    except Exception as e:
                        logger.error(f"Error importing '{file}': {e}")
                        continue

            except Exception as e:
                logger.error(f"Error processing '{file}': {e}")
                continue

            progress.advance(task)

    # Commit everything at once
    conn.commit()
    logger.info("All changes committed successfully")
    logger.info("Summary of tasks:\n"
                f"{format(total_new, ',').replace(',', ' ')} [green]new[/] geometries added, "
                f"{format(total_updated, ',').replace(',', ' ')} [yellow]updated[/] geometries, "
                f"{format(total_identical, ',').replace(',', ' ')} [red]identical[/] geometries skipped")

except Exception as e:
    conn.rollback()  # Rollback the transaction on error
    logger.error(f"An error occurred: {e}. All changes have been rolled back.")
    # Optionally restore from backups here
finally:
    conn.autocommit = True  # Reset autocommit</code></pre>

                <pre><code class="language-python" id="backups-code">
def backup_tables(conn, tables, schema='public'):
    """Create file backups of all affected tables before processing."""
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_dir = os.path.join(os.getcwd(), 'backups')
    backup_info = {}
    
    for table in tables:
        if not check_table_exists(conn, table, schema):
            logger.info(f"Table '{schema}.{table}' does not exist, no backup needed.")
            continue
        
        backup_file = os.path.join(backup_dir, f"{table}_backup_{timestamp}.sql")
        
        try:
            # Create pg_dump command
            cmd = [
                'pg_dump',
                f'--host={conn.info.host}',
                f'--port={conn.info.port}',
                f'--username={conn.info.user}',
                f'--dbname={conn.info.dbname}',
                f'--table={schema}.{table}',
                '--format=p',
                f'--file={backup_file}'
            ]
            
            # Set PGPASSWORD environment variable for the subprocess
            env = os.environ.copy()
            env['PGPASSWORD'] = conn.info.password
            
            # Execute pg_dump
            subprocess.run(cmd, env=env, check=True, capture_output=True)
            
            backup_info[table] = backup_file
            logger.info(f"Created backup of '{schema}.{table}' to '{backup_file}'")
            
            # Manage old backups
            manage_old_backups(backup_dir, table)
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to backup table '{schema}.{table}': {e.stderr.decode()}")
            return None
            
    return backup_info</code></pre>

                <pre><code class="language-python" id="support-formats-code">
def process_files(args, conn, engine, existing_tables, schema):
    total_new = 0
    total_updated = 0
    total_identical = 0

    # Determine file extensions to process
    supported_extensions = ['.shp', '.geojson', '.json', '.gpkg', '.kml', '.gml']

    # Collect files to process (only in specified directory, not subdirectories)
    file_info_list = []

    # List files only in the specified directory
    for file in os.listdir(args.filepath):
        if any(file.lower().endswith(ext) for ext in supported_extensions):
            full_path = os.path.join(args.filepath, file)

            # Skip if not a file (e.g., if it's a directory)
            if not os.path.isfile(full_path):
                continue

            table_name = os.path.splitext(file)[0].lower()

            try:
                gdf = gpd.read_file(full_path)

                # Handle CRS
                source_crs = gdf.crs
                if args.epsg:
                    # User specified an EPSG
                    if source_crs and source_crs.to_epsg() != args.epsg:
                        logger.info(f"Reprojecting from EPSG:{source_crs.to_epsg()} to EPSG:{args.epsg}")
                        gdf.set_crs(source_crs, inplace=True)  # Ensure source CRS is set
                        gdf = gdf.to_crs(epsg=args.epsg)
                    else:
                        gdf.set_crs(epsg=args.epsg, inplace=True)
                elif not source_crs:
                    # No source CRS and no user EPSG specified, default to 4326
                    logger.warning(f"No CRS found in {file}, defaulting to EPSG:4326")
                    gdf.set_crs(epsg=4326, inplace=True)
                else:
                    # Keep source CRS
                    pass

                input_geom_col = gdf.geometry.name
                file_info_list.append({
                    'file': file,
                    'full_path': full_path,
                    'table_name': table_name,
                    'gdf': gdf,
                    'input_geom_col': input_geom_col
                })
            except Exception as e:
                logger.error(f"[red]Error reading '{file}': {e}[/red]")
                continue

    if not file_info_list:
        logger.warning("[red]No spatial files found to process.[/red]")
        return</code></pre>

                <pre><code class="language-python" id="geometry-comparison-code">
def compare_geometries(gdf: GeoDataFrame, conn, table_name: str, geom_column: str = 'geom', schema: str = 'public', exclude_columns: List[str] = None, args=None):
cursor = conn.cursor()

# Get the actual geometry column name from the database
db_geom_column = get_db_geometry_column(conn, table_name, schema=schema)
if not db_geom_column:
    logger.error(f"No geometry column found in table '{schema}.{table_name}'")
    return None, None, None

sql = f"""
SELECT MD5(ST_AsBinary({db_geom_column})) as geom_hash
FROM {schema}.{table_name}
"""

# Get existing geometry hashes from database
existing_hashes = set()
with conn.cursor() as cur:
    cur.execute(sql)
    for row in cur.fetchall():
        existing_hashes.add(row[0])

# Create temporary copy of GDF for comparison
comparison_gdf = gdf.copy()
comparison_gdf['geom_hash'] = comparison_gdf[geom_column].apply(compute_geom_hash)

# Compare with database hashes
new_geometries = []
identical_geometries = []

for idx, row in comparison_gdf.iterrows():
    geom_hash = row['geom_hash']
    if geom_hash in existing_hashes:
        identical_geometries.append(row)
    else:
        new_geometries.append(row)

# Convert lists to GeoDataFrames
new_gdf = GeoDataFrame(new_geometries, geometry=geom_column, crs=gdf.crs) if new_geometries else GeoDataFrame(columns=gdf.columns)
identical_gdf = GeoDataFrame(identical_geometries, geometry=geom_column, crs=gdf.crs) if identical_geometries else GeoDataFrame(columns=gdf.columns)

# Remove temporary hash column
for gdf_temp in [new_gdf, identical_gdf]:
    if 'geom_hash' in gdf_temp.columns:
        gdf_temp.drop('geom_hash', axis=1, inplace=True)

return new_gdf if not new_gdf.empty else None, None, identical_gdf if not identical_gdf.empty else None
                </code></pre>

                <pre><code class="language-python" id="attribute-updates-code">
def update_geometries(gdf, table_name, engine, unique_id_column):
"""Update existing geometries in PostGIS table."""
if gdf is None or gdf.empty:
return

try:
# Create temporary table for updates
temp_table = f"temp_{table_name}"
gdf.to_postgis(temp_table, engine, if_exists='replace', index=False)

with engine.connect() as connection:
    from sqlalchemy import text
    
    # First, check for and add any new columns
    cursor = connection.execute(text(f"""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_schema = 'public' AND table_name = '{table_name}'
    """))
    existing_columns = {row[0] for row in cursor}
    
    # Get new columns from the GeoDataFrame
    new_columns = set(gdf.columns) - existing_columns
    
    # Add any new columns to the main table
    for col in new_columns:
        # Determine column type from GeoDataFrame
        dtype = gdf[col].dtype
        if dtype == 'object':
            sql_type = 'TEXT'
        elif dtype == 'int64':
            sql_type = 'INTEGER'
        elif dtype == 'float64':
            sql_type = 'DOUBLE PRECISION'
        else:
            sql_type = 'TEXT'  # Default to TEXT for unknown types
        
        logger.info(f"Adding new column '{col}' with type {sql_type}")
        connection.execute(text(f'ALTER TABLE "{table_name}" ADD COLUMN IF NOT EXISTS "{col}" {sql_type}'))
    
    # Now proceed with the update
    columns = [col for col in gdf.columns if col != unique_id_column]
    update_cols = ", ".join([f'"{col}" = s."{col}"' for col in columns])
    
    sql = text(f"""
        UPDATE "{table_name}" t
        SET {update_cols}
        FROM "{temp_table}" s
        WHERE t.{unique_id_column} = s.{unique_id_column}
    """)
    logger.debug(f"Executing update SQL: {sql}")
    connection.execute(sql)
    connection.execute(text(f'DROP TABLE IF EXISTS "{temp_table}"'))
    connection.commit()

logger.info(f"Successfully updated {len(gdf)} geometries in {table_name}")
except Exception as e:
logger.error(f"Error updating geometries: {e}")
                </code></pre>

                <pre><code class="language-python" id="geometry-handling-code">
# Collect geometry column names
geom_col_files = defaultdict(list)
for info in file_info_list:
    geom_col_files[info['input_geom_col']].append(info['file'])

# Handle geometry column renaming
for info in file_info_list:
    gdf = info['gdf']
    if gdf.geometry.name != 'geom':
        gdf = gdf.rename_geometry('geom')
        gdf.set_geometry('geom', inplace=True)
        gdf.set_crs(gdf.crs, inplace=True)  # Preserve CRS
        info['gdf'] = gdf
        info['input_geom_col'] = 'geom'
                </code></pre>

                <pre><code class="language-python" id="crs-handling-code">
def check_crs_compatibility(gdf, conn, table_name, geom_column, args):
cursor = conn.cursor()
# Check if the table exists
cursor.execute("""
    SELECT EXISTS (
        SELECT 1
        FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = %s
    );
""", (table_name,))
table_exists = cursor.fetchone()[0]

if not table_exists:
    # Table does not exist, proceed without CRS check
    cursor.close()
    return gdf  # Proceed with the current GeoDataFrame

# Table exists, retrieve existing SRID using ST_SRID
try:
    cursor.execute(f"""
        SELECT ST_SRID("{geom_column}") FROM "{table_name}" WHERE "{geom_column}" IS NOT NULL LIMIT 1;
    """)
    result = cursor.fetchone()
    if result:
        existing_srid = result[0]
        logger.info(f"Existing SRID for '{table_name}' is {existing_srid}")
    else:
        logger.warning(f"No geometries found in '{table_name}' to determine SRID")
        existing_srid = None
except Exception as e:
    logger.error(f"Error retrieving SRID for '{table_name}': {e}")
    conn.rollback()
    cursor.close()
    return None  # Skip this file due to error

# Get the SRID of the new data
new_srid = gdf.crs.to_epsg()
if new_srid is None:
    logger.warning(f"No EPSG code found for the CRS of the new data for '{table_name}'")
    if args.overwrite:
        action = 'y'
    else:
        action = console.input(f"Proceed without CRS check for '{table_name}'? (y/n): ")
    if action.lower() != 'y':
        logger.info(f"Skipping '{table_name}' due to unknown CRS")
        cursor.close()
        return None  # Skip this file
else:
    logger.info(f"CRS of new data for '{table_name}' is EPSG:{new_srid}")

# Compare SRIDs
if existing_srid and new_srid != existing_srid:
    logger.warning(f"CRS mismatch for '{table_name}': Existing SRID {existing_srid}, New SRID {new_srid}")
    if args.overwrite:
        action = 'y'
    else:
        action = console.input(f"Reproject new data to SRID {existing_srid}? (y/n): ")
    if action.lower() == 'y':
        try:
            gdf = gdf.to_crs(epsg=existing_srid)
            logger.info(f"Reprojected new data to SRID {existing_srid}")
        except Exception as e:
            logger.error(f"[red]Error reprojecting data for '{table_name}': {e}[/red]")
            cursor.close()
            return None  # Skip this file due to reprojection error
    else:
        logger.info(f"Skipping '{table_name}' due to CRS mismatch")
        cursor.close()
        return None  # Skip this file
else:
    logger.info(f"CRS is compatible for '{table_name}'")

cursor.close()
return gdf  # Return the (possibly reprojected) GeoDataFrame
                </code></pre>

                <pre><code class="language-python" id="spatial-index-code">
def create_spatial_index(conn, table_name, schema='public', geom_column='geom'):
cursor = conn.cursor()
# Get the actual geometry column name
actual_geom_column = get_db_geometry_column(conn, table_name, schema=schema) or geom_column
index_name = f"{schema}_{table_name}_{actual_geom_column}_idx"

try:
    cursor.execute(f"""
        CREATE INDEX IF NOT EXISTS "{index_name}"
        ON "{schema}"."{table_name}"
        USING GIST ("{actual_geom_column}");
    """)
    conn.commit()
    logger.info(f"Spatial index created on table '{schema}.{table_name}'")
except Exception as e:
    logger.error(f"Error creating spatial index on '{schema}.{table_name}': {e}")
    conn.rollback()
finally:
    cursor.close()</code></pre>
    <pre><code class="language-rust" id="rust-parallel-code">
// Parallel processing implementation
use rayon::prelude::*;  // Parallel processing functionality
use std::collections::HashMap;

let cell_size = buffer_distance * 2.0;
let buffer_distance_squared = buffer_distance * buffer_distance;

// Create spatial grid for efficient neighbor searching
let mut grid: HashMap<(i32, i32), Vec<(usize, (f64, f64))>> = 
    HashMap::with_capacity(points.len() / 10);

// Assign points to grid cells
for (i, &(x, y)) in points.iter().enumerate() {
    let cell = (
        (x / cell_size).floor() as i32,
        (y / cell_size).floor() as i32,
    );
    grid.entry(cell)
        .or_insert_with(Vec::new)
        .push((i, (x, y)));
}

// Process grid cells in parallel
let results: Vec<(usize, usize)> = grid.par_iter()
    .flat_map(|(&(cell_x, cell_y), cell_points)| {
        let mut local_results = Vec::new();
        
        // Check current and neighboring cells
        let neighbor_cells = [
            (cell_x, cell_y),
            (cell_x, cell_y + 1),
            (cell_x + 1, cell_y - 1),
            (cell_x + 1, cell_y),
            (cell_x + 1, cell_y + 1),
        ];
        
        for &neighbor_cell in neighbor_cells.iter() {
            if let Some(neighbor_points) = grid.get(&neighbor_cell) {
                for &(i, (x1, y1)) in cell_points {
                    for &(j, (x2, y2)) in neighbor_points {
                        if i < j {
                            let dx = x1 - x2;
                            let dy = y1 - y2;
                            let distance_squared = dx * dx + dy * dy;
                            if distance_squared <= buffer_distance_squared && distance_squared > 0.0 {
                                local_results.push((i, j));
                            }
                        }
                    }
                }
            }
        }
        local_results
    })
    .collect();
                    </code></pre>
        
                    <pre><code class="language-rust" id="rust-binding-code">
// Python binding setup
use pyo3::prelude::*;
use std::collections::HashMap;
use rayon::prelude::*;

#[pyfunction]
fn points_within_buffer_batch(
    points: Vec<(f64, f64)>, 
    buffer_distance: f64
) -> PyResult<Vec<(usize, usize)>> {
    let cell_size = buffer_distance * 2.0;
    let buffer_distance_squared = buffer_distance * buffer_distance;
    
    let mut grid: HashMap<(i32, i32), Vec<(usize, (f64, f64))>> = 
        HashMap::with_capacity(points.len() / 10);
    
    // Build spatial grid
    for (i, &(x, y)) in points.iter().enumerate() {
        let cell = (
            (x / cell_size).floor() as i32,
            (y / cell_size).floor() as i32,
        );
        grid.entry(cell)
            .or_insert_with(Vec::new)
            .push((i, (x, y)));
    }
    
    // Process points in parallel and find pairs within buffer distance
    let results = grid.par_iter()
        .flat_map(|(&(cell_x, cell_y), cell_points)| {
            let mut local_results = Vec::new();
            let neighbor_cells = [
                (cell_x, cell_y),
                (cell_x, cell_y + 1),
                (cell_x + 1, cell_y - 1),
                (cell_x + 1, cell_y),
                (cell_x + 1, cell_y + 1),
            ];
            
            for &neighbor_cell in neighbor_cells.iter() {
                if let Some(neighbor_points) = grid.get(&neighbor_cell) {
                    for &(i, (x1, y1)) in cell_points {
                        for &(j, (x2, y2)) in neighbor_points {
                            if i < j {
                                let dx = x1 - x2;
                                let dy = y1 - y2;
                                let distance_squared = dx * dx + dy * dy;
                                if distance_squared <= buffer_distance_squared && distance_squared > 0.0 {
                                    local_results.push((i, j));
                                }
                            }
                        }
                    }
                }
            }
            local_results
        })
        .collect();

    Ok(results)
}

#[pymodule]
fn rust_bindings(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(points_within_buffer_batch, m)?)?;
    Ok(())
}
        </code></pre>
                </div>
            </div>
        </div>
                
            </div>
        </div>
    </div>

    
                    
                        <script>
                            document.addEventListener('DOMContentLoaded', () => {
                                // Navigation functionality
                                const navLinks = document.querySelectorAll('.project-nav a');
                                const projects = document.querySelectorAll('.project');
                                
                                function updateActiveLink() {
                                    let currentSection = '';
                                    const headerHeight = document.querySelector('header').offsetHeight;
                                    const scrollPosition = window.scrollY + (window.innerHeight / 3); // Adjust this value as needed

                                    projects.forEach(project => {
                                        const rect = project.getBoundingClientRect();
                                        const projectTop = rect.top + window.scrollY - headerHeight;
                                        const projectBottom = projectTop + project.offsetHeight;

                                        if (scrollPosition >= projectTop && scrollPosition < projectBottom) {
                                            currentSection = project.getAttribute('id');
                                        }
                                    });

                                    navLinks.forEach(link => {
                                        link.classList.remove('active');
                                        if (link.getAttribute('href').substring(1) === currentSection) {
                                            link.classList.add('active');
                                        }
                                    });
                                }
                                
                                window.addEventListener('scroll', updateActiveLink);
                                
                                navLinks.forEach(link => {
                                    link.addEventListener('click', (e) => {
                                        navLinks.forEach(l => l.classList.remove('active'));
                                        e.target.classList.add('active');
                                    });
                                });
                        
                                // Modal functionality
                                const modal = document.getElementById('code-modal');
                                
                                document.querySelectorAll('.view-code-btn').forEach(btn => {
                                    btn.addEventListener('click', () => {
                                        const feature = btn.getAttribute('data-feature');
                                        
                                        // Hide all code blocks
                                        document.querySelectorAll('.modal-body pre').forEach(block => {
                                            block.style.display = 'none';
                                        });
                                        
                                        // Show the selected code block
                                        const codeBlock = document.getElementById(`${feature}-code`);
                                        if (codeBlock) {
                                            codeBlock.parentElement.style.display = 'block';
                                        }
                                        
                                        modal.classList.add('active');
                                        document.body.classList.add('modal-open');
                                        
                                        // Force rehighlight
                                        hljs.highlightAll();
                                    });
                                });
                        
                                // Close modal handlers
                                document.querySelector('.close-modal').addEventListener('click', () => {
                                    modal.classList.remove('active');
                                    document.body.classList.remove('modal-open');
                                });
                        
                                modal.addEventListener('click', (e) => {
                                    if (e.target === modal) {
                                        modal.classList.remove('active');
                                        document.body.classList.remove('modal-open');
                                    }
                                });
                            });
                        </script>
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
                    </body>
                </html>
